{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intense-screening",
   "metadata": {},
   "source": [
    "# Study\n",
    "\n",
    "## Aim\n",
    "\n",
    "Perform scenic analysis with the same data multiple time\n",
    "\n",
    "... sequentially, in a loop\n",
    "(because the pyscenic nextflow pipelines available do not yet run on cluster, July-Aug 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-canada",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compressed-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from arboreto.utils import load_tf_names\n",
    "from arboreto.algo import grnboost2\n",
    "\n",
    "from ctxcore.rnkdb import FeatherRankingDatabase as RankingDatabase\n",
    "from pyscenic.utils import modules_from_adjacencies, load_motifs\n",
    "from pyscenic.prune import prune2df, df2regulons\n",
    "from pyscenic.aucell import aucell\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "talented-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import loompy\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exterior-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sctk as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pacific-plaza",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "'sctk' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mental-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "particular-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extended-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-filename",
   "metadata": {},
   "source": [
    "# Declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "emotional-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "broad-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_FOLDER = \"../Data/Scenic/Databases/\"\n",
    "# from tutorial # SCHEDULER=\"123.122.8.24:8786\"\n",
    "\n",
    "#DATABASES_GLOB = os.path.join(DATABASE_FOLDER, \"hg38__refseq-r80__10kb_up_and_down_tss.mc9nr.feather\")\n",
    "#DATABASES_GLOB = os.path.join(DATABASE_FOLDER, \"hg38__refseq-r80__500bp_up_and_100bp_down_tss.mc9nr.feather\")\n",
    "# \"mm9-*.mc9nr.feather\"\n",
    "#DATABASES_GLOB = os.path.join(DATABASE_FOLDER, \"hg38*.mc9nr.feather\")\n",
    "# \"mm9-*.mc9nr.feather\" and encode_20190621 etc\n",
    "DATABASES_GLOB = os.path.join(DATABASE_FOLDER, \"*.feather\")\n",
    "\n",
    "MOTIF_ANNOTATIONS_FNAME = os.path.join(DATABASE_FOLDER, \"motifs-v9-nr.hgnc-m0.001-o0.0.tbl\")\n",
    "MM_TFS_FNAME = os.path.join(DATABASE_FOLDER, 'motifs-v9-nr.hgnc-m0.001-o0.0.tfs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "demographic-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set study ID and so folder\n",
    "\n",
    "# combination of:\n",
    "\n",
    "# cell types:\n",
    "# 'All' for 'all cell types' not just capillary arterioles\n",
    "\n",
    "# cell subsets:\n",
    "# '200c' for downsampling to 200 cells per cell type\n",
    "# '1kc' for downsampling to 1000 cells per cell type\n",
    "\n",
    "# gene subsets:\n",
    "# 'Hm' for Harmony and the h5ad file keeping resulting embedding\n",
    "# '10kHvg' for top 10,000 most highly variable genes\n",
    "\n",
    "# Data/Scenic study folder name:\n",
    "##studyIdRoot = \"All200c\" # 200 cells per cell type ... and HVG only; head -3  ../Data/Scenic/All200c/Resources/adata_x.csv | awk 'BEGIN{FS=\",\"}{print NF}': 8430\n",
    "##studyIdRoot = \"All200cHm\" # 200 cells per cell type\n",
    "## studyIdRoot = \"All200cHm10kHvg\" # 200 cells per cell type and top10k genes.\n",
    "##studyIdRoot = \"All200cHmTopHvg\" # 200 cells per cell type and top10k genes.\n",
    "##studyIdRoot = \"All1kcHmTopHvg\" # 1000 cells per cell type and top10k genes.\n",
    "studyIdRoot = \"All1kcHm10kHvg\" # 1000 cells per cell type and top10k genes.\n",
    "\n",
    "#.nlargest(3,['lifeExp','gdpPercap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-rendering",
   "metadata": {},
   "source": [
    "# Count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "super-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCES_FOLDER = \"../Data/Scenic/\"+studyIdRoot+\"/Resources/\"\n",
    "Path(RESOURCES_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "SC_EXP_FNAME = os.path.join(RESOURCES_FOLDER, \"adata_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "direct-coverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data/Scenic/All1kcHm10kHvg/Resources/adata_x.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC_EXP_FNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-preliminary",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filter genes or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "large-grounds",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done once ok\n"
     ]
    }
   ],
   "source": [
    "%%script echo done once ok\n",
    "# TODO manual for now, maybe add test on studyID or new variable to keep info on number and/or type of genes\n",
    "\n",
    "# count matrix to sample genes from:\n",
    "# (mind cells may/will have been downsamples already)\n",
    "#adata = sc.read_h5ad('../Data/Scenic/Hdf5/fskOrg_'+'All200c'+'_hm.h5ad')\n",
    "adata = sc.read_h5ad('../Data/Scenic/Hdf5/fskOrg_'+'All1kc'+'_hm.h5ad')\n",
    "\n",
    "print(adata.shape)\n",
    "\n",
    "# dispersions_norm:\n",
    "#--------------------\n",
    "\n",
    "##adata.var.nlargest(3,['dispersions_norm'])\n",
    "##adata.var.nlargest(3,['dispersions_norm']).index.values.tolist()\n",
    "#####adata.var['highly_variable'].value_counts()\n",
    "\n",
    "# filter genes:\n",
    "#--------------------\n",
    "\n",
    "# 10.000 genes the most variables:\n",
    "adata = adata[:,adata.var.nlargest(10000,['dispersions_norm']).index.values.tolist()]\n",
    "\n",
    "# highly variable genes: 'highly_variable':\n",
    "####adata = adata[:,adata.var['highly_variable'] == True]\n",
    "\n",
    "print(adata.shape)\n",
    "\n",
    "# UMAP X_pca_harmony:\n",
    "#--------------------\n",
    "\n",
    "sc.pl.embedding(adata,\n",
    "                basis='X_pca_harmony',\n",
    "                color=['dataset', 'annotToUse2'],\n",
    "                title=['dataset', 'annotToUse2'],\n",
    "                ncols=2,\n",
    "                use_raw=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-medicaid",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write count matrix to file\n",
    "\n",
    "Unless file exists already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "annual-saturn",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done once ok\n"
     ]
    }
   ],
   "source": [
    "%%script echo done once ok\n",
    "# TODO: maybe add test for existence of file.\n",
    "\n",
    "## Count matrix\n",
    "print('Count matrix')\n",
    "pd.DataFrame(data=adata.X.transpose(), #.todense(),\n",
    "         index=adata.var_names.tolist(),\n",
    "         columns=adata.obs_names.tolist()).to_csv(SC_EXP_FNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sitting-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(fname):\n",
    "    return os.path.splitext(os.path.basename(fname))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-recall",
   "metadata": {},
   "source": [
    "## Read count matrix in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "north-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33945, 10000)\n"
     ]
    }
   ],
   "source": [
    "ex_matrix = pd.read_csv(SC_EXP_FNAME, sep=',', header=0, index_col=0).T\n",
    "print(ex_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-monster",
   "metadata": {},
   "source": [
    "# Perform scenic analysis with the same data multiple time\n",
    "\n",
    "... sequentially, in a loop\n",
    "(because the pyscenic nextflow pipelines available do not yet run on cluster, July-Aug 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-cycle",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "All1kcHm10kHvg8\n",
      "Count matrix\n",
      "Run scenic\n",
      "(33945, 10000)\n",
      "[FeatherRankingDatabase(name=\"hg38__refseq-r80__500bp_up_and_100bp_down_tss.mc9nr\"), FeatherRankingDatabase(name=\"encode_20190621__ChIP_seq_transcription_factor.hg38__refseq-r80__10kb_up_and_down_tss.max\"), FeatherRankingDatabase(name=\"hg38__refseq-r80__10kb_up_and_down_tss.mc9nr\"), FeatherRankingDatabase(name=\"encode_20190621__ChIP_seq_transcription_factor.hg38__refseq-r80__500bp_up_and_100bp_down_tss.max\")]\n",
      "Adjacencies file: ../Data/Scenic/All1kcHm10kHvg8/Output/adjMat.csv\n",
      "preparing dask client\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Numba: Attempted to fork from a non-main thread, the TBB library may be in an invalid state in the child process.\n",
      "Numba: Attempted to fork from a non-main thread, the TBB library may be in an invalid state in the child process.\n",
      "Numba: Attempted to fork from a non-main thread, the TBB library may be in an invalid state in the child process.\n",
      "Numba: Attempted to fork from a non-main thread, the TBB library may be in an invalid state in the child process.\n",
      "Numba: Attempted to fork from a non-main thread, the TBB library may be in an invalid state in the child process.\n",
      "Numba: Attempted to fork from a non-main thread, the TBB library may be in an invalid state in the child process.\n",
      "Numba: Attempted to fork from a non-main thread, the TBB library may be in an invalid state in the child process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing input\n",
      "creating dask graph\n",
      "6 partitions\n",
      "computing dask graph\n"
     ]
    }
   ],
   "source": [
    "#for i in range(0,1):\n",
    "#for i in range(7,8):\n",
    "for i in range(8,9):    \n",
    "    gc.collect()\n",
    "    print(i)\n",
    "    # Data/Scenic study folder name\n",
    "    studyId = studyIdRoot+str(i) # x cells per cell type\n",
    "    print(studyId)\n",
    "    fnRoot = \"fskOrg_\"+studyId\n",
    "\n",
    "    # path:\n",
    "    #--------------\n",
    "    \n",
    "    # _filtered\n",
    "    # ie after gene and cell filtering\n",
    "    ##adata = sc.read_h5ad('../Data/Scenic/Hdf5/fskOrg_'+'All200c'+'_hm.h5ad')\n",
    "        # only needed to extract count matrix for each run if we want to.\n",
    "    ##print(adata.shape)\n",
    "    Path(\"../Data/Scenic/\"+studyId+\"/Output/\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(\"../Data/Scenic/\"+studyId+\"/Resources/\").mkdir(parents=True, exist_ok=True)\n",
    "    DATA_FOLDER = \"../Data/Scenic/\"+studyId+\"/Output/\"\n",
    "    #RESOURCES_FOLDER = \"../Data/Scenic/\"+studyId+\"/Resources/\" # fine to keep matrix for each run but not necessary.\n",
    "    RESOURCES_FOLDER = \"../Data/Scenic/\"+studyIdRoot+\"/Resources/\"\n",
    "    SC_EXP_FNAME = os.path.join(RESOURCES_FOLDER, \"adata_x.csv\")\n",
    "\n",
    "    ## Count matrix\n",
    "    #--------------\n",
    "\n",
    "    print('Count matrix')\n",
    "    # Write count matrix to file:\n",
    "    # ... unless looping for multiruns:\n",
    "    \n",
    "    ##pd.DataFrame(data=adata.X.transpose(), #.todense(),\n",
    "    ##         index=adata.var_names.tolist(),\n",
    "    ##         columns=adata.obs_names.tolist()).to_csv(SC_EXP_FNAME)\n",
    "\n",
    "    # output files:\n",
    "    #--------------\n",
    "\n",
    "    REGULONS_FNAME = os.path.join(DATA_FOLDER, \"regulons.p\")\n",
    "    #MOTIFS_FNAME = os.path.join(DATA_FOLDER, \"motifs.csv\")\n",
    "    ENRICHEDMOTIF_FNAME = os.path.join(DATA_FOLDER, \"enrichedMotifs.csv\")\n",
    "    AUCMEANS_FNAME = os.path.join(DATA_FOLDER, \"aucMeans.csv\")\n",
    "    \n",
    "    # run scenic:\n",
    "    #--------------\n",
    "    \n",
    "    print('Run scenic')\n",
    "    ### yes but not here, see above, read that in once only ## ex_matrix = pd.read_csv(SC_EXP_FNAME, sep=',', header=0, index_col=0).T\n",
    "    print(ex_matrix.shape) # cells x genes (2097, 3282) or (19249, 2725)\n",
    "    tf_names = load_tf_names(MM_TFS_FNAME)\n",
    "    db_fnames = glob.glob(DATABASES_GLOB)\n",
    "    dbs = [RankingDatabase(fname=fname, name=name(fname)) for fname in db_fnames]\n",
    "    print(dbs)\n",
    "\n",
    "    # compute adjacency matrix:\n",
    "    #---------------------------\n",
    "    ADJMAT_FNAME = os.path.join(DATA_FOLDER, \"adjMat.csv\")\n",
    "    print(f'Adjacencies file: {ADJMAT_FNAME}')\n",
    "    adjacencies = grnboost2(ex_matrix, tf_names=tf_names, verbose=True)\n",
    "\n",
    "    # write adjacency matrix to file:\n",
    "    # adjMat.csv\n",
    "    #---------------------------\n",
    "    adjacencies.to_csv(ADJMAT_FNAME)\n",
    "    \n",
    "    # Compute modules:\n",
    "    #---------------------------   \n",
    "    print('Modules')\n",
    "    modules = list(modules_from_adjacencies(adjacencies, ex_matrix))\n",
    "    print(f'Motif file: {ENRICHEDMOTIF_FNAME}')\n",
    "\n",
    "    # Calculate a list of enriched motifs and the corresponding target genes for all modules.\n",
    "    #---------------------------\n",
    "    with ProgressBar():\n",
    "        enrichedMotifs = prune2df(dbs, modules, MOTIF_ANNOTATIONS_FNAME, num_workers=10) # see pruning option to avoid warnings\n",
    "\n",
    "    # write adjacency matrix to file:\n",
    "    # enrichedMotifs.csv\n",
    "    #---------------------------\n",
    "    enrichedMotifs.to_csv(ENRICHEDMOTIF_FNAME)\n",
    "    print(f'Regulons {REGULONS_FNAME}')\n",
    "\n",
    "    # Create regulons from this table of enriched motifs.\n",
    "    #---------------------------\n",
    "    regulons = df2regulons(enrichedMotifs)\n",
    "    \n",
    "    # Save the discovered regulons to disk:\n",
    "    # * regulons.p\n",
    "    # * auc_mtx.csv\n",
    "    #---------------------------\n",
    "    with open(REGULONS_FNAME, \"wb\") as f:\n",
    "        pickle.dump(regulons, f)\n",
    "        \n",
    "    print(ex_matrix.shape)\n",
    "    print('auc_mtx')\n",
    "    auc_mtx = aucell(ex_matrix, regulons, num_workers=10)\n",
    "    print(auc_mtx.shape)\n",
    "    auc_mtx.to_csv(DATA_FOLDER+\"auc_mtx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-closing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
